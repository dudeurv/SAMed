{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dudeurv/SAMed/blob/main/BraTS_SAMed_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-tSMFkgPhyc"
      },
      "source": [
        "# Download codes, pretrained weights and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id3D1PuuLQMm"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmmYvx7FLUif",
        "outputId": "030875d1-820e-4875-e9e2-5c02eedbfc98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops==0.6.1\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n",
            "Collecting icecream==2.1.3\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting colorama>=0.3.9 (from icecream==2.1.3)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream==2.1.3) (2.16.1)\n",
            "Collecting executing>=0.3.1 (from icecream==2.1.3)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream==2.1.3)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream==2.1.3) (1.16.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.4.1 colorama-0.4.6 executing-2.0.1 icecream-2.1.3\n",
            "Collecting MedPy==0.4.0\n",
            "  Downloading MedPy-0.4.0.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from MedPy==0.4.0) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from MedPy==0.4.0) (1.23.5)\n",
            "Collecting SimpleITK>=1.1.0 (from MedPy==0.4.0)\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: MedPy\n",
            "  Building wheel for MedPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MedPy: filename=MedPy-0.4.0-py3-none-any.whl size=214949 sha256=c3218cddb850cba83bf677e53537db4deb9e4d974a5e45f4f68d87a1fd71119e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/32/c7/6380ab2edb8cca018d39a0f1d43250fd9791922c963117de46\n",
            "Successfully built MedPy\n",
            "Installing collected packages: SimpleITK, MedPy\n",
            "Successfully installed MedPy-0.4.0 SimpleITK-2.3.1\n",
            "Collecting monai==1.1.0\n",
            "  Downloading monai-1.1.0-202212191849-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from monai==1.1.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from monai==1.1.0) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->monai==1.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->monai==1.1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->monai==1.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->monai==1.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->monai==1.1.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->monai==1.1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->monai==1.1.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->monai==1.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->monai==1.1.0) (1.3.0)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-1.1.0\n",
            "Collecting opencv_python==4.5.4.58\n",
            "  Downloading opencv_python-4.5.4.58-cp310-cp310-manylinux2014_x86_64.whl (60.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv_python==4.5.4.58) (1.23.5)\n",
            "Installing collected packages: opencv_python\n",
            "  Attempting uninstall: opencv_python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "Successfully installed opencv_python-4.5.4.58\n",
            "Collecting SimpleITK==2.2.1\n",
            "  Downloading SimpleITK-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "  Attempting uninstall: SimpleITK\n",
            "    Found existing installation: SimpleITK 2.3.1\n",
            "    Uninstalling SimpleITK-2.3.1:\n",
            "      Successfully uninstalled SimpleITK-2.3.1\n",
            "Successfully installed SimpleITK-2.2.1\n",
            "Collecting tensorboardX==2.6\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX==2.6) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX==2.6) (23.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX==2.6) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n",
            "Collecting ml-collections==0.1.1\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections==0.1.1) (1.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections==0.1.1) (6.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml-collections==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections==0.1.1) (21.6.0)\n",
            "Building wheels for collected packages: ml-collections\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94505 sha256=44700d22a4d2d4e5466cae0caf309946238ddf6eacfdd1855f63b662d640a281\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "Successfully built ml-collections\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.1\n",
            "Collecting onnx==1.13.1\n",
            "  Downloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.1) (1.23.5)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.1) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.1) (4.5.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.13.1\n",
            "Collecting onnxruntime==1.14.1\n",
            "  Downloading onnxruntime-1.14.1-cp310-cp310-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime==1.14.1)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.14.1) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.14.1) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.14.1) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.14.1) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.14.1) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.14.1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.14.1) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.1\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install einops==0.6.1\n",
        "!pip install icecream==2.1.3\n",
        "!pip install MedPy==0.4.0\n",
        "!pip install monai==1.1.0\n",
        "!pip install opencv_python==4.5.4.58\n",
        "!pip install SimpleITK==2.2.1\n",
        "!pip install tensorboardX==2.6\n",
        "!pip install ml-collections==0.1.1\n",
        "!pip install onnx==1.13.1\n",
        "!pip install onnxruntime==1.14.1\n",
        "!pip install tensorboardX\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF-Hl0fZGTRq"
      },
      "source": [
        "# Download codes, pretrained weights and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyB2eYACPtEX",
        "outputId": "b3125a15-641a-477f-ad2f-e21f06d95aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'samed_codes'...\n",
            "remote: Enumerating objects: 533, done.\u001b[K\n",
            "remote: Counting objects: 100% (410/410), done.\u001b[K\n",
            "remote: Compressing objects: 100% (217/217), done.\u001b[K\n",
            "remote: Total 533 (delta 277), reused 274 (delta 190), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (533/533), 794.39 KiB | 16.55 MiB/s, done.\n",
            "Resolving deltas: 100% (296/296), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['subsample_datasets.py',\n",
              " 'requirements.txt',\n",
              " '.gitignore',\n",
              " 'eval_BraTS.py',\n",
              " 'BraTS_SAMed_train_command_line.ipynb',\n",
              " 'segment_anything',\n",
              " '.git',\n",
              " 'trainer.py',\n",
              " 'utils.py',\n",
              " 'datasets',\n",
              " 'lists',\n",
              " 'materials',\n",
              " 'dataset_BraTS.py',\n",
              " 'train.py',\n",
              " 'preprocess',\n",
              " 'README.md',\n",
              " 'test.py',\n",
              " 'sam_lora_image_encoder_mask_decoder.py',\n",
              " 'sam_lora_image_encoder.py',\n",
              " 'train_BraTS.py',\n",
              " 'trainer_BraTS.py']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "CODE_DIR = 'samed_codes'\n",
        "\n",
        "# Create the parent directory\n",
        "os.makedirs(f'./{CODE_DIR}', exist_ok=True)\n",
        "\n",
        "# Clone the SAMed repository into its subfolder\n",
        "!git clone https://github.com/dudeurv/SAMed.git $CODE_DIR\n",
        "\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qo3WFc4NsXGy"
      },
      "outputs": [],
      "source": [
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True\n",
        "\n",
        "class Downloader(object):\n",
        "  def __init__(self, use_pydrive):\n",
        "    self.use_pydrive = use_pydrive\n",
        "    current_directory = os.getcwd()\n",
        "    self.save_dir = '.'\n",
        "    if self.use_pydrive:\n",
        "      self.authenticate()\n",
        "\n",
        "  def authenticate(self):\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    self.drive = GoogleDrive(gauth)\n",
        "\n",
        "  def download_file(self, file_id, file_name):\n",
        "    file_dst = f'{self.save_dir}/{file_name}'\n",
        "    if os.path.exists(file_dst):\n",
        "      print(f'{file_name} already exists')\n",
        "      return\n",
        "    downloaded = self.drive.CreateFile({'id': file_id})\n",
        "    downloaded.FetchMetadata(fetch_all=True)\n",
        "    downloaded.GetContentFile(file_dst)\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)\n",
        "\n",
        "sam_model = {'id': '1_oCdoEEu3mNhRfFxeWyRerOKt8OEUvcg', 'name': 'sam_vit_b_01ec64.pth'}\n",
        "downloader.download_file(file_id=sam_model['id'], file_name=sam_model['name'])\n",
        "data = {'id': '1nHZWlCBpudbT4zzPyqyu2Vi5uILcxSrv', 'name': 'Slices.zip'}\n",
        "downloader.download_file(file_id=data['id'], file_name=data['name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-sxSFzwwvNyB"
      },
      "outputs": [],
      "source": [
        "!unzip -n Slices.zip -d /content/samed_codes/ > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ModmC4zTSSQj"
      },
      "source": [
        "# Execute SAMed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***From trainer.py***"
      ],
      "metadata": {
        "id": "uqqgeTAZErnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLjKoVzbFvlC",
        "outputId": "2e1f7866-9388-4b84-f98a-e99ca097dde5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.nn.modules.loss import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from utils import DiceLoss, Focal_loss\n",
        "from torchvision import transforms\n",
        "from icecream import ic\n",
        "\n",
        "from eval_BraTS import test_per_epoch, vis_per_epoch, calc_loss\n",
        "\n",
        "def trainer_BraTS(args, model, snapshot_path, multimask_output, low_res):\n",
        "    from dataset_BraTS import BraTS_dataset\n",
        "    base_lr = args.base_lr\n",
        "    num_classes = args.num_classes\n",
        "    batch_size = args.batch_size * args.n_gpu\n",
        "    # max_iterations = args.max_iterations\n",
        "    db_train = BraTS_dataset(base_dir=args.root_path)\n",
        "    db_test = BraTS_dataset(base_dir='/content/samed_codes/Slices/Test')\n",
        "    print(\"The length of train set is: {}\".format(len(db_train)))\n",
        "\n",
        "    def worker_init_fn(worker_id):\n",
        "        random.seed(args.seed + worker_id)\n",
        "\n",
        "    trainloader = DataLoader(db_train, batch_size=5, shuffle=True, num_workers=8, pin_memory=True,\n",
        "                             worker_init_fn=worker_init_fn)\n",
        "    testloader = DataLoader(db_test, batch_size=10, shuffle=True, num_workers=8, pin_memory=True,\n",
        "                             worker_init_fn=worker_init_fn)\n",
        "    if args.n_gpu > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "    model.train()\n",
        "\n",
        "    if args.warmup:\n",
        "        b_lr = base_lr / args.warmup_period\n",
        "    else:\n",
        "        b_lr = base_lr\n",
        "    if args.AdamW:\n",
        "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=b_lr, betas=(0.9, 0.999), weight_decay=0.1)\n",
        "    else:\n",
        "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=b_lr, momentum=0.9, weight_decay=0.0001)  # Even pass the model.parameters(), the `requires_grad=False` layers will not update\n",
        "    writer = SummaryWriter(snapshot_path + '/log')\n",
        "    iter_num = 0\n",
        "    max_epoch = args.max_epochs\n",
        "    stop_epoch = args.stop_epoch\n",
        "    best_epoch, best_loss = 0.0, np.inf\n",
        "    max_iterations = args.max_epochs * len(trainloader)  # max_epoch = max_iterations // len(trainloader) + 1\n",
        "    print(\"{} iterations per epoch. {} max iterations \".format(len(trainloader), max_iterations))\n",
        "    best_performance = 0.0\n",
        "    iterator = tqdm(range(max_epoch), ncols=70)\n",
        "    for epoch_num in iterator:\n",
        "        for i_batch, (image_batch, label_batch) in enumerate(trainloader):\n",
        "            # Original shape of image and label batch\n",
        "\n",
        "            image_batch, label_batch = image_batch.unsqueeze(1).float().cuda(), label_batch.unsqueeze(1).cuda()\n",
        "            image_batch = image_batch.repeat(1, 3, 1, 1)\n",
        "            # Resize the target\n",
        "            label_batch = F.interpolate(label_batch, size=(128, 128), mode='nearest')\n",
        "            label_batch = label_batch.squeeze(1)\n",
        "\n",
        "            label_batch = torch.clamp(label_batch, 0, num_classes-1)\n",
        "\n",
        "            assert image_batch.max() <= 3, f'image_batch max: {image_batch.max()}'\n",
        "            outputs = model(image_batch, multimask_output, args.img_size)\n",
        "            # Check the shape and content of the model output\n",
        "\n",
        "            loss, loss_ce, loss_dice = calc_loss(outputs, label_batch, args.dice_param, num_classes)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if args.warmup and iter_num < args.warmup_period:\n",
        "                lr_ = base_lr * ((iter_num + 1) / args.warmup_period)\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_\n",
        "            else:\n",
        "                if args.warmup:\n",
        "                    shift_iter = iter_num - args.warmup_period\n",
        "                    assert shift_iter >= 0, f'Shift iter is {shift_iter}, smaller than zero'\n",
        "                else:\n",
        "                    shift_iter = iter_num\n",
        "                lr_ = base_lr * (1.0 - shift_iter / max_iterations) ** 0.9  # learning rate adjustment depends on the max iterations\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_\n",
        "\n",
        "        # Testing at the end of each epoch\n",
        "        test_loss, test_loss_ce, test_loss_dice = test_per_epoch(model, testloader, multimask_output, args.img_size)\n",
        "\n",
        "        # Update best model if current epoch's loss is lower\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            best_epoch = epoch_num\n",
        "            torch.save(model.state_dict(), os.path.join(snapshot_path, 'model_best_epoch_{:03d}.pth'.format(best_epoch)))\n",
        "            print(\"New best model saved with loss {:.4f}\".format(best_loss))\n",
        "\n",
        "        # Log at the end of each epoch\n",
        "        print(f'--- Epoch {epoch_num}/{args.max_epochs}: Training loss = {loss:.4f}, Testing loss = {test_loss:.4f}, Best loss = {best_loss:.4f}, Best epoch = {best_epoch}')\n",
        "\n",
        "        if (epoch_num + 1) % 2 == 0 or epoch_num >= args.max_epochs or epoch_num >= args.stop_epoch :\n",
        "            save_mode_path = os.path.join(snapshot_path, 'epoch_{:03d}.pth'.format(epoch_num))\n",
        "            torch.save(model.state_dict(), save_mode_path)\n",
        "            print(\"Model saved to {}\".format(save_mode_path))\n",
        "            if epoch_num >= args.max_epochs - 1 or epoch_num >= args.stop_epoch - 1:\n",
        "                iterator.close()\n",
        "                break\n",
        "\n",
        "    writer.close()\n",
        "    return \"Training Finished!\""
      ],
      "metadata": {
        "id": "pfZK9Fl1Ewl3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***From train.py***"
      ],
      "metadata": {
        "id": "hsbI7rA0EdEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from importlib import import_module\n",
        "\n",
        "from sam_lora_image_encoder import LoRA_Sam\n",
        "from segment_anything import sam_model_registry\n",
        "\n",
        "from icecream import ic\n",
        "\n",
        "# Manually set the arguments\n",
        "args = argparse.Namespace(\n",
        "    root_path='/content/samed_codes/Slices/Train',\n",
        "    output='/content/samed_codes/training_output',\n",
        "    dataset='BraTS',\n",
        "    num_classes=8,\n",
        "    max_iterations=100,\n",
        "    max_epochs=10,\n",
        "    stop_epoch=11,\n",
        "    batch_size=10,\n",
        "    n_gpu=2,\n",
        "    deterministic=1,\n",
        "    base_lr=0.005,\n",
        "    img_size=512,\n",
        "    seed=1234,\n",
        "    vit_name='vit_b',\n",
        "    ckpt='/content/samed_codes/sam_vit_b_01ec64.pth',\n",
        "    lora_ckpt=None,\n",
        "    rank=4,\n",
        "    warmup=True,  # True if you want to use warmup\n",
        "    warmup_period=250,\n",
        "    AdamW=True,  # True if you want to use AdamW\n",
        "    module='sam_lora_image_encoder',\n",
        "    dice_param=0.8\n",
        ")\n",
        "\n",
        "\n",
        "if not args.deterministic:\n",
        "    cudnn.benchmark = True\n",
        "    cudnn.deterministic = False\n",
        "else:\n",
        "    cudnn.benchmark = False\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed(args.seed)\n",
        "dataset_name = args.dataset\n",
        "dataset_config = {\n",
        "    'BraTS': {\n",
        "        'root_path': args.root_path,\n",
        "        'num_classes': args.num_classes,\n",
        "    }\n",
        "}\n",
        "args.is_pretrain = True\n",
        "args.exp = dataset_name + '_' + str(args.img_size)\n",
        "snapshot_path = os.path.join(args.output, \"{}\".format(args.exp))\n",
        "snapshot_path = snapshot_path + '_pretrain' if args.is_pretrain else snapshot_path\n",
        "snapshot_path += '_' + args.vit_name\n",
        "snapshot_path = snapshot_path + '_' + str(args.max_iterations)[\n",
        "                                      0:2] + 'k' if args.max_iterations != 30000 else snapshot_path\n",
        "snapshot_path = snapshot_path + '_epo' + str(args.max_epochs) if args.max_epochs != 30 else snapshot_path\n",
        "snapshot_path = snapshot_path + '_bs' + str(args.batch_size)\n",
        "snapshot_path = snapshot_path + '_lr' + str(args.base_lr) if args.base_lr != 0.01 else snapshot_path\n",
        "snapshot_path = snapshot_path + '_s' + str(args.seed) if args.seed != 1234 else snapshot_path\n",
        "\n",
        "if not os.path.exists(snapshot_path):\n",
        "    os.makedirs(snapshot_path)\n",
        "\n",
        "# register model\n",
        "sam, img_embedding_size = sam_model_registry[args.vit_name](image_size=args.img_size,\n",
        "                                                            num_classes=args.num_classes,\n",
        "                                                            checkpoint=args.ckpt, pixel_mean=[0, 0, 0],\n",
        "                                                            pixel_std=[1, 1, 1])\n",
        "\n",
        "pkg = import_module(args.module)\n",
        "net = pkg.LoRA_Sam(sam, args.rank).cuda()\n",
        "\n",
        "# net = LoRA_Sam(sam, args.rank).cuda()\n",
        "if args.lora_ckpt is not None:\n",
        "    net.load_lora_parameters(args.lora_ckpt)\n",
        "\n",
        "if args.num_classes > 1:\n",
        "    multimask_output = True\n",
        "else:\n",
        "    multimask_output = False\n",
        "\n",
        "low_res = img_embedding_size * 4\n",
        "\n",
        "config_file = os.path.join(snapshot_path, 'config.txt')\n",
        "config_items = []\n",
        "for key, value in args.__dict__.items():\n",
        "    config_items.append(f'{key}: {value}\\n')\n",
        "\n",
        "with open(config_file, 'w') as f:\n",
        "    f.writelines(config_items)\n",
        "\n",
        "trainer = {'BraTS': trainer_BraTS}\n",
        "trainer[dataset_name](args, net, snapshot_path, multimask_output, low_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "01ORU0VADVCd",
        "outputId": "e6cb7e00-569d-4e76-859a-89e0de4987d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 1])\n",
            "The length of train set is: 1395\n",
            "279 iterations per epoch. 2790 max iterations \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|███▎                             | 1/10 [05:13<46:58, 313.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with loss 0.6990\n",
            "--- Epoch 0/10: Training loss = 0.7132, Testing loss = 0.6990, Best loss = 0.6990, Best epoch = 0\n",
            "New best model saved with loss 0.2946\n",
            "--- Epoch 1/10: Training loss = 0.3918, Testing loss = 0.2946, Best loss = 0.2946, Best epoch = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██████▌                          | 2/10 [10:29<42:02, 315.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_001.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|█████████▉                       | 3/10 [15:46<36:50, 315.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with loss 0.2888\n",
            "--- Epoch 2/10: Training loss = 0.1009, Testing loss = 0.2888, Best loss = 0.2888, Best epoch = 2\n",
            "New best model saved with loss 0.2861\n",
            "--- Epoch 3/10: Training loss = 0.2718, Testing loss = 0.2861, Best loss = 0.2861, Best epoch = 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|█████████████▏                   | 4/10 [21:03<31:37, 316.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_003.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████████████████▌                | 5/10 [26:19<26:21, 316.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with loss 0.2803\n",
            "--- Epoch 4/10: Training loss = 0.2755, Testing loss = 0.2803, Best loss = 0.2803, Best epoch = 4\n",
            "--- Epoch 5/10: Training loss = 0.3133, Testing loss = 0.2864, Best loss = 0.2803, Best epoch = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|███████████████████▊             | 6/10 [31:35<21:04, 316.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_005.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████████████████████          | 7/10 [36:51<15:48, 316.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 6/10: Training loss = 0.3089, Testing loss = 0.2933, Best loss = 0.2803, Best epoch = 4\n",
            "--- Epoch 7/10: Training loss = 0.1938, Testing loss = 0.2931, Best loss = 0.2803, Best epoch = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|██████████████████████████▍      | 8/10 [42:07<10:32, 316.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_007.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████████████████████████▋   | 9/10 [47:23<05:16, 316.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 8/10: Training loss = 0.3954, Testing loss = 0.3034, Best loss = 0.2803, Best epoch = 4\n",
            "--- Epoch 9/10: Training loss = 0.2982, Testing loss = 0.2948, Best loss = 0.2803, Best epoch = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████████████████████████▋   | 9/10 [52:39<05:51, 351.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_009.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Training Finished!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from dataset_BraTS import BraTS_dataset\n",
        "import matplotlib as plt\n",
        "\n",
        "# Define a function to calculate the confusion matrix from predictions and ground truths\n",
        "def calculate_confusion_matrix_from_arrays(prediction, ground_truth, nr_labels):\n",
        "    # Stack the ground truth and prediction arrays and transpose\n",
        "    replace_indices = np.vstack((\n",
        "        ground_truth.flatten(),\n",
        "        prediction.flatten())\n",
        "    ).T\n",
        "    # Compute the confusion matrix using histogram\n",
        "    confusion_matrix, _ = np.histogramdd(\n",
        "        replace_indices,\n",
        "        bins=(nr_labels, nr_labels),  # Number of bins for each dimension (nr_labels)\n",
        "        range=[(0, nr_labels), (0, nr_labels)]  # Range of labels\n",
        "    )\n",
        "    # Convert the confusion matrix to uint32 for consistency\n",
        "    confusion_matrix = confusion_matrix.astype(np.uint32)\n",
        "    return confusion_matrix\n",
        "\n",
        "# Define a function to calculate the Dice coefficient from the confusion matrix\n",
        "def calculate_dice(confusion_matrix):\n",
        "    dices = []  # Initialize a list to store Dice scores for each class\n",
        "    # Iterate over each class to calculate Dice score\n",
        "    for index in range(confusion_matrix.shape[0]):\n",
        "        true_positives = confusion_matrix[index, index]  # Diagonal elements are true positives\n",
        "        # Sum of the column for the class minus true positives gives false positives\n",
        "        false_positives = confusion_matrix[:, index].sum() - true_positives\n",
        "        # Sum of the row for the class minus true positives gives false negatives\n",
        "        false_negatives = confusion_matrix[index, :].sum() - true_positives\n",
        "        # The denominator in the Dice score formula\n",
        "        denom = 2 * true_positives + false_positives + false_negatives\n",
        "        # Handle the case where denominator is zero (to avoid division by zero)\n",
        "        if denom == 0:\n",
        "            dice = 0\n",
        "        else:\n",
        "            # Dice score calculation: 2 times the number of true positives divided by the denominator\n",
        "            dice = 2 * float(true_positives) / denom\n",
        "        dices.append(dice)  # Append the Dice score for the current class to the list\n",
        "    return dices\n",
        "\n",
        "\n",
        "# Define a function to test the model for an epoch and visualize the results\n",
        "def vis_per_epoch(model, testloader, multimask_output, img_size):\n",
        "    model.eval()\n",
        "    num_classes = 8\n",
        "    fig, axs = plt.subplots(len(testloader), 3, figsize=(1*3, len(testloader)*1), subplot_kw=dict(xticks=[],yticks=[]))\n",
        "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.uint32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i_batch, (image_batch, label_batch) in enumerate(testloader):\n",
        "\n",
        "            image_batch, label_batch = image_batch.unsqueeze(1).float().cuda(), label_batch.unsqueeze(1).cuda()\n",
        "            image_batch = image_batch.repeat(1, 3, 1, 1)\n",
        "\n",
        "            label_batch = F.interpolate(label_batch, size=(128, 128), mode='nearest')\n",
        "            label_batch = label_batch.squeeze(1)\n",
        "\n",
        "            label_batch = torch.clamp(label_batch, 0, num_classes-1)\n",
        "\n",
        "            output = model(image_batch, multimask_output, img_size)\n",
        "            logits = outputs['low_res_logits']\n",
        "\n",
        "            prob = F.softmax(logits, dim=1)\n",
        "            pred_seg = torch.argmax(prob, dim=1)\n",
        "\n",
        "            confusion_matrix += calculate_confusion_matrix_from_arrays(pred_seg.cpu(), labels.cpu(), num_classes)\n",
        "\n",
        "            img_num = 0\n",
        "            axs[batch_idx, 0].imshow(images[img_num, 0].cpu().numpy(), cmap='gray')\n",
        "            axs[batch_idx, 1].imshow(labels[img_num].cpu().numpy(), cmap='gray')\n",
        "            axs[batch_idx, 2].imshow(pred_seg[img_num].cpu().numpy(), cmap='gray')\n",
        "\n",
        "    confusion_matrix = confusion_matrix[1:, 1:]\n",
        "\n",
        "    dices_per_class = {'dice_cls:{}'.format(cls + 1): dice\n",
        "                for cls, dice in enumerate(calculate_dice(confusion_matrix))}\n",
        "\n",
        "    plt.axis('OFF')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return dices_per_class\n",
        "\n",
        "import torch\n",
        "from importlib import import_module\n",
        "\n",
        "# Assuming your model's setup is like this\n",
        "sam, img_embedding_size = sam_model_registry[args.vit_name](image_size=args.img_size,\n",
        "                                                            num_classes=args.num_classes,\n",
        "                                                            checkpoint=args.ckpt, pixel_mean=[0, 0, 0],\n",
        "                                                            pixel_std=[1, 1, 1])\n",
        "pkg = import_module(args.module)\n",
        "net = pkg.LoRA_Sam(sam, args.rank).cuda()\n",
        "\n",
        "# Load the saved model\n",
        "saved_model_path = '/content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_009.pth'\n",
        "net.load_state_dict(torch.load(saved_model_path))\n",
        "\n",
        "from dataset_BraTS import BraTS_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the test dataset\n",
        "db_test = BraTS_dataset(base_dir='/content/samed_codes/Slices/Test')\n",
        "test_loader = DataLoader(db_test, batch_size=10, shuffle=False, num_workers=2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Switch to evaluation mode\n",
        "net.eval()\n",
        "\n",
        "# Run visualization and evaluation\n",
        "dices_per_class = vis_per_epoch(net, test_loader, multimask_output, img_size=128)  # img_size should match the expected input size of your model\n",
        "\n",
        "# Output the results\n",
        "print(\"Dices per class:\", dices_per_class)\n",
        "print(\"Overall Dice:\", np.mean(list(dices_per_class.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "8rBj62mOPsge",
        "outputId": "b89b1aaf-eaa8-4ca8-f39b-cee8bc8cb848"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 1])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ccfd63694511>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# Load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0msaved_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_009.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset_BraTS\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBraTS_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LoRA_Sam:\n\tMissing key(s) in state_dict: \"sam.image_encoder.pos_embed\", \"sam.image_encoder.patch_embed.proj.weight\", \"sam.image_encoder.patch_embed.proj.bias\", \"sam.image_encoder.blocks.0.norm1.weight\", \"sam.image_encoder.blocks.0.norm1.bias\", \"sam.image_encoder.blocks.0.attn.rel_pos_h\", \"sam.image_encoder.blocks.0.attn.rel_pos_w\", \"sam.image_encoder.blocks.0.attn.qkv.qkv.weight\", \"sam.image_encoder.blocks.0.attn.qkv.qkv.bias\", \"sam.image_encoder.blocks.0.attn.qkv.linear_a_q.weight\", \"sam.image_encoder.blocks.0.attn.qkv.linear_b_q.weight\", \"sam.image_encoder.blocks.0.attn.qkv.linear_a_v.weight\", \"sam.image_encoder.blocks.0.attn.qkv.linear_b_v.weight\", \"sam.image_encoder.blocks.0.attn.proj.weight\", \"sam.image_encoder.blocks.0.attn.proj.bias\", \"sam.image_encoder.blocks.0.norm2.weight\", \"sam.image_encoder.blocks.0.norm2.bias\", \"sam.image_encoder.blocks.0.mlp.lin1.weight\", \"sam.image_encoder.blocks.0.mlp.lin1.bias\", \"sam.image_encoder.blocks.0.mlp.lin2.weight\", \"sam.image_encoder.blocks.0.mlp.lin2.bias\", \"sam.image_encoder.blocks.1.norm1.weight\", \"sam.image_encoder.blocks.1.norm1.bias\", \"sam.image_encoder.blocks.1.attn.rel_pos_h\", \"sam.image_encoder.blocks.1.attn.rel_pos_w\", \"sam.image_encoder.blocks.1.attn.qkv.qkv.weight\", \"sam.image_encoder.blocks.1.attn.qkv.qkv.bias\", \"sam.image_encoder.blocks.1.attn.qkv.linear_a_q.weight\", \"sam.image_encoder.blocks.1.attn.qkv.linear_b_q.weight\", \"sam.image_encoder.blocks.1.attn.qkv.linear_a_v.weight\", \"sam.image_encoder.blocks.1.attn.qkv.linear_b_v....\n\tUnexpected key(s) in state_dict: \"module.sam.image_encoder.pos_embed\", \"module.sam.image_encoder.patch_embed.proj.weight\", \"module.sam.image_encoder.patch_embed.proj.bias\", \"module.sam.image_encoder.blocks.0.norm1.weight\", \"module.sam.image_encoder.blocks.0.norm1.bias\", \"module.sam.image_encoder.blocks.0.attn.rel_pos_h\", \"module.sam.image_encoder.blocks.0.attn.rel_pos_w\", \"module.sam.image_encoder.blocks.0.attn.qkv.qkv.weight\", \"module.sam.image_encoder.blocks.0.attn.qkv.qkv.bias\", \"module.sam.image_encoder.blocks.0.attn.qkv.linear_a_q.weight\", \"module.sam.image_encoder.blocks.0.attn.qkv.linear_b_q.weight\", \"module.sam.image_encoder.blocks.0.attn.qkv.linear_a_v.weight\", \"module.sam.image_encoder.blocks.0.attn.qkv.linear_b_v.weight\", \"module.sam.image_encoder.blocks.0.attn.proj.weight\", \"module.sam.image_encoder.blocks.0.attn.proj.bias\", \"module.sam.image_encoder.blocks.0.norm2.weight\", \"module.sam.image_encoder.blocks.0.norm2.bias\", \"module.sam.image_encoder.blocks.0.mlp.lin1.weight\", \"module.sam.image_encoder.blocks.0.mlp.lin1.bias\", \"module.sam.image_encoder.blocks.0.mlp.lin2.weight\", \"module.sam.image_encoder.blocks.0.mlp.lin2.bias\", \"module.sam.image_encoder.blocks.1.norm1.weight\", \"module.sam.image_encoder.blocks.1.norm1.bias\", \"module.sam.image_encoder.blocks.1.attn.rel_pos_h\", \"module.sam.image_encoder.blocks.1.attn.rel_pos_w\", \"module.sam.image_encoder.blocks.1.attn.qkv.qkv.weight\", \"module.sam.image_encoder.blocks.1.attn.qkv.qkv.bias\", \"module.sam.image_encoder.b..."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}